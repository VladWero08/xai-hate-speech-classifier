{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.10.0+cu130)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: scipy in /venv/main/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: datasets in /venv/main/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: nltk in /venv/main/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: transformers in /venv/main/lib/python3.12/site-packages (5.1.0)\n",
      "Requirement already satisfied: lime in /venv/main/lib/python3.12/site-packages (0.2.0.1)\n",
      "Requirement already satisfied: shap in /venv/main/lib/python3.12/site-packages (0.50.0)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: matplotlib in /venv/main/lib/python3.12/site-packages (3.10.8)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /venv/main/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /venv/main/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: cuda-bindings==13.0.3 in /venv/main/lib/python3.12/site-packages (from torch) (13.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.88 in /venv/main/lib/python3.12/site-packages (from torch) (13.0.88)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.96 in /venv/main/lib/python3.12/site-packages (from torch) (13.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.85 in /venv/main/lib/python3.12/site-packages (from torch) (13.0.85)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.15.1.9 in /venv/main/lib/python3.12/site-packages (from torch) (9.15.1.9)\n",
      "Requirement already satisfied: nvidia-cublas==13.1.0.3 in /venv/main/lib/python3.12/site-packages (from torch) (13.1.0.3)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.0.0.61)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /venv/main/lib/python3.12/site-packages (from torch) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.4.66 in /venv/main/lib/python3.12/site-packages (from torch) (12.0.4.66)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.3.3 in /venv/main/lib/python3.12/site-packages (from torch) (12.6.3.3)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /venv/main/lib/python3.12/site-packages (from torch) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.28.9 in /venv/main/lib/python3.12/site-packages (from torch) (2.28.9)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.4.5 in /venv/main/lib/python3.12/site-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.85 in /venv/main/lib/python3.12/site-packages (from torch) (13.0.85)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.88 in /venv/main/lib/python3.12/site-packages (from torch) (13.0.88)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.1.6 in /venv/main/lib/python3.12/site-packages (from torch) (1.15.1.6)\n",
      "Requirement already satisfied: triton==3.6.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /venv/main/lib/python3.12/site-packages (from cuda-bindings==13.0.3->torch) (1.3.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.12/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: numpy<2.7,>=1.26.4 in /venv/main/lib/python3.12/site-packages (from scipy) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /venv/main/lib/python3.12/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /venv/main/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /venv/main/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /venv/main/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /venv/main/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /venv/main/lib/python3.12/site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /venv/main/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /venv/main/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /venv/main/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /venv/main/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.0)\n",
      "Requirement already satisfied: click in /venv/main/lib/python3.12/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /venv/main/lib/python3.12/site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /venv/main/lib/python3.12/site-packages (from nltk) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /venv/main/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /venv/main/lib/python3.12/site-packages (from lime) (1.8.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /venv/main/lib/python3.12/site-packages (from lime) (0.26.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /venv/main/lib/python3.12/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /venv/main/lib/python3.12/site-packages (from shap) (0.63.1)\n",
      "Requirement already satisfied: cloudpickle in /venv/main/lib/python3.12/site-packages (from shap) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /venv/main/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /venv/main/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /venv/main/lib/python3.12/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /venv/main/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.12/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /venv/main/lib/python3.12/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /venv/main/lib/python3.12/site-packages (from numba>=0.54->shap) (0.46.0)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /venv/main/lib/python3.12/site-packages (from scikit-image>=0.12->lime) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /venv/main/lib/python3.12/site-packages (from scikit-image>=0.12->lime) (2026.2.15)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /venv/main/lib/python3.12/site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch requests scipy datasets nltk transformers lime shap pandas datasets nltk matplotlib scipy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7BDjAQYgGpLW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import re\n",
    "import random\n",
    "from io import StringIO\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "import scipy as sp\n",
    "\n",
    "import shap\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e0952712e849149eca3d50864be314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4a62ea2ca742a891abcad1ba034720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7389bbf9448c42339fed89e8ab153897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa590acdf874d9087ff497d88245e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6869363f486d475ea4ad54e47bb0327a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dd6d862a4c4e0295bb2c4b412efebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0015f2f916de4abeaac4348bd008078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: facebook/roberta-hate-speech-dynabench-r4-target\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}!\")\n",
    "\n",
    "model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "NON_HATE_SPEECH_CLASS = 0\n",
    "HATE_SPEECH_CLASS = 1\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, output_attentions=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'i want to cut your throat, dont then to kill you!!!!'\n",
      "Tokens: ['<s>', 'i', 'Ġwant', 'Ġto', 'Ġcut', 'Ġyour', 'Ġthroat', ',', 'Ġdont', 'Ġthen', 'Ġto', 'Ġkill', 'Ġyou', '!!!!', '</s>']\n",
      "Predicted label: hate\n",
      "Confidence: 0.9969\n"
     ]
    }
   ],
   "source": [
    "text = \"i want to cut your throat, dont then to kill you!!!!\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "outputs = model(**inputs)\n",
    "probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "predicted_class_id = probabilities.argmax().item()\n",
    "predicted_label = model.config.id2label[predicted_class_id]\n",
    "predicted_score = probabilities[0][predicted_class_id].item()\n",
    "\n",
    "print(f\"Text: '{text}'\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "print(f\"Confidence: {predicted_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word_token(token: str) -> bool:\n",
    "  global tokenizer\n",
    "\n",
    "  if token in tokenizer.all_special_tokens:\n",
    "    return False\n",
    "\n",
    "  token = token.lstrip(\"Ġ\")\n",
    "  return any(c.isalpha() for c in token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00311355, 0.99688643]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_probabilities(text: str) -> torch.Tensor:\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "  probabilities = F.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "  return probabilities\n",
    "\n",
    "# [0]: non hate speech\n",
    "# [1]: hate speech\n",
    "get_probabilities(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StMtMo5dN3rI",
    "outputId": "0f4235e3-1c6e-4c0a-b4c4-33db73f93741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate Speech Tweets Dataset\n",
      "Shape: (500, 147)\n",
      "Columns: ['comment_id', 'annotator_id', 'platform', 'sentiment', 'respect', 'insult', 'humiliate', 'status', 'dehumanize', 'violence', 'genocide', 'attack_defend', 'hatespeech', 'hate_speech_score', 'text', 'infitms', 'outfitms', 'annotator_severity', 'std_err', 'annotator_infitms', 'annotator_outfitms', 'hypothesis', 'target_race_asian', 'target_race_black', 'target_race_latinx', 'target_race_middle_eastern', 'target_race_native_american', 'target_race_pacific_islander', 'target_race_white', 'target_race_other', 'race', 'target_religion_atheist', 'target_religion_buddhist', 'target_religion_christian', 'target_religion_hindu', 'target_religion_jewish', 'target_religion_mormon', 'target_religion_muslim', 'target_religion_other', 'religion', 'target_origin_immigrant', 'target_origin_migrant_worker', 'target_origin_specific_country', 'target_origin_undocumented', 'target_origin_other', 'origin', 'target_gender_men', 'target_gender_non_binary', 'target_gender_transgender_men', 'target_gender_transgender_unspecified', 'target_gender_transgender_women', 'target_gender_women', 'target_gender_other', 'gender', 'target_sexuality_bisexual', 'target_sexuality_gay', 'target_sexuality_lesbian', 'target_sexuality_straight', 'target_sexuality_other', 'sexuality', 'target_age_children', 'target_age_teenagers', 'target_age_young_adults', 'target_age_middle_aged', 'target_age_seniors', 'target_age_other', 'age', 'target_disability_physical', 'target_disability_cognitive', 'target_disability_neurological', 'target_disability_visually_impaired', 'target_disability_hearing_impaired', 'target_disability_unspecific', 'target_disability_other', 'disability', 'target_politics_alt_right', 'target_politics_communist', 'target_politics_conservative', 'target_politics_democrat', 'target_politics_green_party', 'target_politics_leftist', 'target_politics_liberal', 'target_politics_libertarian', 'target_politics_republican', 'target_politics_socialist', 'target_politics_other', 'politics', 'annotator_gender', 'annotator_trans', 'annotator_educ', 'annotator_income', 'annotator_ideology', 'annotator_gender_men', 'annotator_gender_women', 'annotator_gender_non_binary', 'annotator_gender_prefer_not_to_say', 'annotator_gender_self_describe', 'annotator_transgender', 'annotator_cisgender', 'annotator_transgender_prefer_not_to_say', 'annotator_education_some_high_school', 'annotator_education_high_school_grad', 'annotator_education_some_college', 'annotator_education_college_grad_aa', 'annotator_education_college_grad_ba', 'annotator_education_professional_degree', 'annotator_education_masters', 'annotator_education_phd', 'annotator_income_<10k', 'annotator_income_10k-50k', 'annotator_income_50k-100k', 'annotator_income_100k-200k', 'annotator_income_>200k', 'annotator_ideology_extremeley_conservative', 'annotator_ideology_conservative', 'annotator_ideology_slightly_conservative', 'annotator_ideology_neutral', 'annotator_ideology_slightly_liberal', 'annotator_ideology_liberal', 'annotator_ideology_extremeley_liberal', 'annotator_ideology_no_opinion', 'annotator_race_asian', 'annotator_race_black', 'annotator_race_latinx', 'annotator_race_middle_eastern', 'annotator_race_native_american', 'annotator_race_pacific_islander', 'annotator_race_white', 'annotator_race_other', 'annotator_age', 'annotator_religion_atheist', 'annotator_religion_buddhist', 'annotator_religion_christian', 'annotator_religion_hindu', 'annotator_religion_jewish', 'annotator_religion_mormon', 'annotator_religion_muslim', 'annotator_religion_nothing', 'annotator_religion_other', 'annotator_sexuality_bisexual', 'annotator_sexuality_gay', 'annotator_sexuality_straight', 'annotator_sexuality_other', 'hate_speech_label', 'attention_scores', 'lime_scores', 'shap_scores']\n",
      "First 5 rows:\n",
      "   comment_id  annotator_id  platform  sentiment  respect  insult  humiliate  \\\n",
      "0        99.0       10913.0       0.0        4.0      4.0     4.0        4.0   \n",
      "1       233.0        9241.0       0.0        4.0      3.0     3.0        1.0   \n",
      "2       254.0        3473.0       0.0        4.0      4.0     4.0        3.0   \n",
      "3       268.0        4734.0       0.0        4.0      4.0     4.0        3.0   \n",
      "4       341.0        2342.0       0.0        4.0      4.0     4.0        4.0   \n",
      "\n",
      "   status  dehumanize  violence  ...  annotator_religion_nothing  \\\n",
      "0     2.0         2.0       1.0  ...                         0.0   \n",
      "1     3.0         1.0       3.0  ...                         1.0   \n",
      "2     4.0         3.0       4.0  ...                         0.0   \n",
      "3     4.0         3.0       1.0  ...                         0.0   \n",
      "4     4.0         3.0       0.0  ...                         0.0   \n",
      "\n",
      "   annotator_religion_other  annotator_sexuality_bisexual  \\\n",
      "0                       0.0                           0.0   \n",
      "1                       0.0                           0.0   \n",
      "2                       1.0                           1.0   \n",
      "3                       0.0                           0.0   \n",
      "4                       0.0                           0.0   \n",
      "\n",
      "   annotator_sexuality_gay annotator_sexuality_straight  \\\n",
      "0                      0.0                          1.0   \n",
      "1                      0.0                          4.0   \n",
      "2                      0.0                          0.0   \n",
      "3                      0.0                          3.0   \n",
      "4                      0.0                          1.0   \n",
      "\n",
      "   annotator_sexuality_other  hate_speech_label  \\\n",
      "0                        0.0          sexuality   \n",
      "1                        0.0             origin   \n",
      "2                        0.0             gender   \n",
      "3                        0.0             origin   \n",
      "4                        0.0             gender   \n",
      "\n",
      "                                    attention_scores  \\\n",
      "0  [('Eat', 0.7766950652003288), ('cock', 1.14172...   \n",
      "1  [('I', 0.19648334383964539), ('fucking', 0.041...   \n",
      "2  [('kill', 0.4272181987762451), ('yourself', 0....   \n",
      "3  [('Fuck', 0.7315737754106522), ('those', 0.980...   \n",
      "4  [('Fuck', 0.13556696008890867), ('off', 0.2353...   \n",
      "\n",
      "                                         lime_scores  \\\n",
      "0  [('die', 0.28463358798038796), ('cock', 0.2259...   \n",
      "1  [('I', -0.4461398306860246), ('your', 0.169252...   \n",
      "2  [('fucking', 0.06955680805083102), ('idiot', 0...   \n",
      "3  [('Saudi', 0.758144916183556), ('Fuck', 0.3467...   \n",
      "4  [('cunt', 0.35290730887026917), ('nazi', -0.21...   \n",
      "\n",
      "                                         shap_scores  \n",
      "0  [('Eat ', 0.2769965330759684), ('cock ', 0.225...  \n",
      "1  [('I ', 0.9005785882472992), ('fucking ', 0.02...  \n",
      "2  [('kill ', -0.27785372734069824), ('yourself '...  \n",
      "3  [('Fuck ', 2.010564684867859), ('those ', 0.35...  \n",
      "4  [('Fuck ', 0.7194043695926666), ('off ', 0.332...  \n",
      "\n",
      "[5 rows x 147 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/VladWero08/xai-hate-speech-classifier/refs/heads/main/dataset/hate_speech_dataset_with_explainers.csv\"\n",
    "response = requests.get(dataset_url)\n",
    "ucb_hate_speech_df = pd.read_csv(StringIO(response.text), sep=\",\")\n",
    "    \n",
    "print(\"Hate Speech Tweets Dataset\")\n",
    "print(\"Shape:\", ucb_hate_speech_df.shape)\n",
    "print(\"Columns:\", ucb_hate_speech_df.columns.tolist())\n",
    "print(\"First 5 rows:\")\n",
    "print(ucb_hate_speech_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explainers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.19648334383964539),\n",
       " ('fucking', 0.04118870850652456),\n",
       " ('H', 0.18134414218366146),\n",
       " ('ATE', 0.33032047376036644),\n",
       " ('americ', 0.8735839948058128),\n",
       " ('ans', 0.5834043361246586),\n",
       " ('.', 0.5437215864658356),\n",
       " ('I', 0.181207574903965),\n",
       " ('hope', 0.06883443333208561),\n",
       " ('your', 0.19421817548573017),\n",
       " ('country', 0.10570773109793663),\n",
       " ('BUR', 0.0880456380546093),\n",
       " ('NS', 0.07501181587576866),\n",
       " ('.', 0.5369281955063343)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_token_attention_score(\n",
    "  attentions: tuple[torch.Tensor],\n",
    "  token_pos: int,\n",
    "  last_n_layers: int = 4\n",
    ") -> float:\n",
    "  \"\"\"\n",
    "  Given the attention matrix resulted from BERT inference, and a token position,\n",
    "  computes the attention score for that token by summing the attention of the\n",
    "  last 4 layers of BERT.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  attentions : tuple[torch.Tensor]\n",
    "             Attention resulted from BERT inference of a tokenized paragraph.\n",
    "  token_pos  : int\n",
    "             Position of the token, should be > 0 (class token)\n",
    "  \"\"\"\n",
    "  # (num_layers, num_heads, query, key)\n",
    "  # the query in this case will be token 0, corresponding to the class token\n",
    "  # the key in this case will be the token_pos received as parameter\n",
    "  attention_score = 0\n",
    "  for i in range(len(attentions) - 1, len(attentions) - last_n_layers - 1, -1):\n",
    "      attention_score += attentions[i][:, :, 0, token_pos].mean().item()\n",
    "\n",
    "  return attention_score\n",
    "\n",
    "def compute_attention_scores(\n",
    "    attentions: tuple[torch.Tensor],\n",
    "    tokens: list[str],\n",
    "    last_n_layers: int = 4\n",
    ") -> list[tuple]:\n",
    "  \"\"\"\n",
    "  Given the attention matrix resulted from BERT inference, computes the attention\n",
    "  score for each token by summing the attention of the last 4 layers of BERT.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  attentions : tuple[torch.Tensor]\n",
    "              Attention resulted from BERT inference of a tokenized paragraph.\n",
    "  \"\"\"\n",
    "  global tokenizer\n",
    "  attention_scores = []\n",
    "\n",
    "  for i in range(len(tokens)):\n",
    "    token = tokens[i].lstrip(\"Ġ\")\n",
    "    attention_scores.append(\n",
    "        (token, compute_token_attention_score(attentions, i, last_n_layers))\n",
    "    )\n",
    "\n",
    "  return attention_scores\n",
    "\n",
    "inputs = tokenizer(ucb_hate_speech_df[:4][\"text\"].tolist()[1], return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "outputs = model(**inputs)\n",
    "\n",
    "compute_attention_scores(outputs.attentions, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', -0.4584079330608032),\n",
       " ('BURNS', -0.14306140561571845),\n",
       " ('fucking', 0.13477088462484987),\n",
       " ('your', 0.1080903565336436),\n",
       " ('HATE', 0.08692601050602869),\n",
       " ('americans', -0.04190788188265134),\n",
       " ('country', -0.04098660678550688),\n",
       " ('hope', 0.03739524395181921)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_lime_scores(\n",
    "  text: str,\n",
    "  tokens: list[str],\n",
    "  label: int = HATE_SPEECH_CLASS,\n",
    "  num_samples: int = 100,\n",
    ") -> dict:\n",
    "  \"\"\"\n",
    "  Given a text, its tokens and the predicted class by the hate speech classifier, it\n",
    "  uses LIME to extract the importance of each token. The number of features used by\n",
    "  the LimeTextExplainer is equal to the total number of non special tokens.\n",
    "  \"\"\"\n",
    "  global model, tokenizer\n",
    "\n",
    "  # compute the number of features as the number of tokens different from the special ones\n",
    "  num_features = len([token for token in tokens if token not in tokenizer.all_special_tokens])\n",
    "\n",
    "  # define the LIME explainer\n",
    "  explainer = LimeTextExplainer(class_names=list(model.config.id2label.values()))\n",
    "  explanation = explainer.explain_instance(\n",
    "      text,\n",
    "      get_probabilities,\n",
    "      num_features=num_features,\n",
    "      num_samples=num_samples,\n",
    "  )\n",
    "\n",
    "  # extract the LIME scores and store them in a dictionary\n",
    "  feature_attributions = explanation.as_list(label=label)\n",
    "  tokens = [(word.item(), score) for _, (word, score) in enumerate(feature_attributions)]\n",
    "\n",
    "  return tokens\n",
    "\n",
    "# compute the LIME score for the tokens in the example sentence\n",
    "compute_lime_scores(ucb_hate_speech_df[:4][\"text\"].tolist()[1], tokens, predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I ', 0.9005785882472992),\n",
       " ('fucking ', 0.027191132307052612),\n",
       " ('H', 0.11832618117332458),\n",
       " ('ATE ', 0.29801749587059023),\n",
       " ('americ', 0.1651911675930023),\n",
       " ('ans', 0.1309647500514984),\n",
       " ('. ', 0.415344113111496),\n",
       " ('I ', 0.174204843384879),\n",
       " ('hope ', 0.42708660875047955),\n",
       " ('your ', 0.27539290700639996),\n",
       " ('country ', 0.16818346296037948),\n",
       " ('BUR', 0.09716351543154034),\n",
       " ('NS', 0.003816204411642876),\n",
       " ('.', 0.01946146999086651)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a prediction function\n",
    "def f(x):\n",
    "    tv = torch.tensor([tokenizer.encode(v, padding=\"max_length\", max_length=500, truncation=True, add_special_tokens=False) for v in x]).to(device)\n",
    "    with torch.no_grad():\n",
    "      outputs = model(tv)[0].detach().cpu().numpy()\n",
    "    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
    "    val = sp.special.logit(scores[:, 1])  # use one vs rest logit units\n",
    "    return val\n",
    "\n",
    "# build an explainer using a token masker\n",
    "shap_explainer = shap.Explainer(f, tokenizer)\n",
    "\n",
    "def compute_shap_scores(text: str) -> np.ndarray:\n",
    "  global shap_explainer\n",
    "  shap_values = shap_explainer([text], fixed_context=1, batch_size=1)\n",
    "  shap_values_list = []\n",
    "\n",
    "  for i, value in enumerate(shap_values.values[0]):\n",
    "      token = shap_values.data[0][i]\n",
    "      if token == '' or token in tokenizer.all_special_tokens:\n",
    "          continue\n",
    "\n",
    "      shap_values_list.append((token, value.item()))\n",
    "\n",
    "  return shap_values_list\n",
    "\n",
    "compute_shap_scores(ucb_hate_speech_df[:4][\"text\"].tolist()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGRAIi-uOciK"
   },
   "source": [
    "## **Distribution Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUwy2T-tOkX5"
   },
   "source": [
    "For each sample, the normalized entropy, gini and top-5 mass coefficients are computed, and afterwards these metrics will be averaged per hate speech category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzXn56bNOjeu",
    "outputId": "4bdde031-11b0-4649-b81f-29ce1b9e9938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.359\n",
      "Gini: 0.5667\n",
      "Top-5 Mass: 1.0\n"
     ]
    }
   ],
   "source": [
    "def compute_entropy(distribution: list[float]) -> float:\n",
    "  n = len(distribution)\n",
    "  entropy = -sum([p * np.log2(p) for p in distribution]) / np.log2(n)\n",
    "  entropy = np.round(entropy, 4)\n",
    "  return entropy\n",
    "\n",
    "def compute_gini(distribution: list[float]) -> float:\n",
    "  distribution = np.sort(distribution)\n",
    "  n = len(distribution)\n",
    "\n",
    "  i = np.arange(1, n + 1)\n",
    "  gini = 1 - 2 * np.sum(distribution * (n - i + 0.5) / n)\n",
    "\n",
    "  return np.round(gini, 4)\n",
    "\n",
    "def compute_top_k_mass(\n",
    "    distribution: list[float],\n",
    "    k: int = 5,\n",
    ") -> float:\n",
    "  k = min(len(distribution), k)\n",
    "  distribution = np.sort(distribution)[::-1]\n",
    "  distribution = distribution[:k]\n",
    "  mass = np.sum(distribution)\n",
    "\n",
    "  return mass\n",
    "\n",
    "distribution = [0.05, 0.9, 0.05]\n",
    "print(f\"Entropy: {compute_entropy(distribution)}\")\n",
    "print(f\"Gini: {compute_gini(distribution)}\")\n",
    "print(f\"Top-5 Mass: {compute_top_k_mass(distribution)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WMjhciSvSQ_Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n",
      "/tmp/ipykernel_2891/2290216194.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[[\n"
     ]
    }
   ],
   "source": [
    "def compute_comparison_metrics(row):\n",
    "  attention = F.softmax(torch.Tensor([score for token, score in ast.literal_eval(row[\"attention_scores\"])]), dim=0).tolist()\n",
    "  lime = F.softmax(torch.Tensor([score for token, score in ast.literal_eval(row[\"lime_scores\"])]), dim=0).tolist()\n",
    "  shap = F.softmax(torch.Tensor([score for token, score in ast.literal_eval(row[\"shap_scores\"])]), dim=0).tolist()\n",
    "\n",
    "  # attention distribution metrics\n",
    "  attention_entropy = compute_entropy(attention)\n",
    "  attention_gini = compute_gini(attention)\n",
    "  attention_top_k_mass = compute_top_k_mass(attention)\n",
    "\n",
    "  # lime distribution metrics\n",
    "  lime_entropy = compute_entropy(lime)\n",
    "  lime_gini = compute_gini(lime)\n",
    "  lime_top_k_mass = compute_top_k_mass(lime)\n",
    "\n",
    "  # shap distribution metrics\n",
    "  shap_entropy = compute_entropy(shap)\n",
    "  shap_gini = compute_gini(shap)\n",
    "  shap_top_k_mass = compute_top_k_mass(shap)\n",
    "\n",
    "  return pd.Series({\n",
    "    'attention_entropy':      np.round(attention_entropy, 4),\n",
    "    'attention_gini':         np.round(attention_gini, 4),\n",
    "    'attention_top_k_mass':   np.round(attention_top_k_mass, 4),\n",
    "    'lime_entropy':           np.round(lime_entropy, 4),\n",
    "    'lime_gini':              np.round(lime_gini, 4),\n",
    "    'lime_top_k_mass':        np.round(lime_top_k_mass, 4),\n",
    "    'shap_entropy':           np.round(shap_entropy, 4),\n",
    "    'shap_gini':              np.round(shap_gini, 4),\n",
    "    'shap_top_k_mass':        np.round(shap_top_k_mass, 4)\n",
    "  })\n",
    "\n",
    "# apply to entire dataframe\n",
    "ucb_hate_speech_df[[\n",
    "  'attention_entropy',\n",
    "  'attention_gini',\n",
    "  'attention_top_k_mass',\n",
    "  'lime_entropy',\n",
    "  'lime_gini',\n",
    "  'lime_top_k_mass',\n",
    "  'shap_entropy',\n",
    "  'shap_gini',\n",
    "  'shap_top_k_mass'\n",
    "]] = ucb_hate_speech_df.apply(compute_comparison_metrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s31p_8puVKOb",
    "outputId": "20f6298e-fa14-43ef-e2eb-2755d4692cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics = attention_entropy\n",
      "hate_speech_label\n",
      "gender       0.987397\n",
      "origin       0.988522\n",
      "race         0.989092\n",
      "religion     0.988492\n",
      "sexuality    0.992650\n",
      "Name: attention_entropy, dtype: float64\n",
      "\n",
      "Metrics = attention_gini\n",
      "hate_speech_label\n",
      "gender       0.092174\n",
      "origin       0.093591\n",
      "race         0.085079\n",
      "religion     0.084955\n",
      "sexuality    0.078559\n",
      "Name: attention_gini, dtype: float64\n",
      "\n",
      "Metrics = attention_top_k_mass\n",
      "hate_speech_label\n",
      "gender       0.449039\n",
      "origin       0.358162\n",
      "race         0.406818\n",
      "religion     0.362582\n",
      "sexuality    0.610836\n",
      "Name: attention_top_k_mass, dtype: float64\n",
      "\n",
      "Metrics = lime_entropy\n",
      "hate_speech_label\n",
      "gender       0.993632\n",
      "origin       0.996073\n",
      "race         0.994454\n",
      "religion     0.993900\n",
      "sexuality    0.989986\n",
      "Name: lime_entropy, dtype: float64\n",
      "\n",
      "Metrics = lime_gini\n",
      "hate_speech_label\n",
      "gender       0.063598\n",
      "origin       0.056510\n",
      "race         0.057544\n",
      "religion     0.061757\n",
      "sexuality    0.067141\n",
      "Name: lime_gini, dtype: float64\n",
      "\n",
      "Metrics = lime_top_k_mass\n",
      "hate_speech_label\n",
      "gender       0.513129\n",
      "origin       0.422327\n",
      "race         0.506876\n",
      "religion     0.457579\n",
      "sexuality    0.753845\n",
      "Name: lime_top_k_mass, dtype: float64\n",
      "\n",
      "Metrics = shap_entropy\n",
      "hate_speech_label\n",
      "gender       0.944939\n",
      "origin       0.964319\n",
      "race         0.958258\n",
      "religion     0.956896\n",
      "sexuality    0.934848\n",
      "Name: shap_entropy, dtype: float64\n",
      "\n",
      "Metrics = shap_gini\n",
      "hate_speech_label\n",
      "gender       0.218074\n",
      "origin       0.181979\n",
      "race         0.194507\n",
      "religion     0.192248\n",
      "sexuality    0.228379\n",
      "Name: shap_gini, dtype: float64\n",
      "\n",
      "Metrics = shap_top_k_mass\n",
      "hate_speech_label\n",
      "gender       0.519321\n",
      "origin       0.403662\n",
      "race         0.465957\n",
      "religion     0.416905\n",
      "sexuality    0.684081\n",
      "Name: shap_top_k_mass, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = ['attention_entropy', 'attention_gini', 'attention_top_k_mass', 'lime_entropy', 'lime_gini', 'lime_top_k_mass', 'shap_entropy', 'shap_gini', 'shap_top_k_mass']\n",
    "\n",
    "for metric in metrics:\n",
    "  average_by_category = ucb_hate_speech_df.groupby('hate_speech_label')[metric].mean()\n",
    "\n",
    "  print(f\"Metrics = {metric}\")\n",
    "  print(average_by_category)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YoN3qJooZK-7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2891/2981819.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[['attention_shap_spearman', 'attention_shap_kendall', 'attention_shap_jaccard']] = ucb_hate_speech_df.apply(compute_rank_metrics, axis=1)\n",
      "/tmp/ipykernel_2891/2981819.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[['attention_shap_spearman', 'attention_shap_kendall', 'attention_shap_jaccard']] = ucb_hate_speech_df.apply(compute_rank_metrics, axis=1)\n",
      "/tmp/ipykernel_2891/2981819.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ucb_hate_speech_df[['attention_shap_spearman', 'attention_shap_kendall', 'attention_shap_jaccard']] = ucb_hate_speech_df.apply(compute_rank_metrics, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def top_k_jaccard(a: list[float], b: list[float], k: int = 5):\n",
    "  k = min(len(a), k)\n",
    "  top_k_tokens_a = set([token for token, score in sorted(a, key=lambda x: x[1], reverse=True)[:k]])\n",
    "  top_k_tokens_b = set([token for token, score in sorted(b, key=lambda x: x[1], reverse=True)[:k]])\n",
    "\n",
    "  intersection = len(top_k_tokens_a & top_k_tokens_b)\n",
    "  union = len(top_k_tokens_a | top_k_tokens_b)\n",
    "  jaccard_index = intersection / union if union > 0 else 0\n",
    "\n",
    "  return jaccard_index\n",
    "\n",
    "def compute_rank_metrics(row):\n",
    "  attention = F.softmax(torch.Tensor([score for token, score in ast.literal_eval(row[\"attention_scores\"])]), dim=0).tolist()\n",
    "  shap = F.softmax(torch.Tensor([score for token, score in ast.literal_eval(row[\"shap_scores\"])]), dim=0).tolist()\n",
    "\n",
    "  spearman_corr, spearman_pval = spearmanr(attention, shap)\n",
    "  kendall_corr, kendall_pval = kendalltau(attention, shap)\n",
    "  jaccard_index = top_k_jaccard(\n",
    "    a=ast.literal_eval(row[\"attention_scores\"]),\n",
    "    b=ast.literal_eval(row[\"shap_scores\"]),\n",
    "  )\n",
    "\n",
    "  return pd.Series({\n",
    "    'attention_shap_spearman':  np.round(spearman_corr, 4),\n",
    "    'attention_shap_kendall':   np.round(kendall_corr, 4),\n",
    "    'attention_shap_jaccard':   np.round(jaccard_index, 4)\n",
    "  })\n",
    "\n",
    "# apply to entire dataframe\n",
    "ucb_hate_speech_df[['attention_shap_spearman', 'attention_shap_kendall', 'attention_shap_jaccard']] = ucb_hate_speech_df.apply(compute_rank_metrics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDbhHWl4bpCG",
    "outputId": "0fc2662d-631d-4c64-ca19-9cc44fa2f20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics = attention_shap_spearman\n",
      "hate_speech_label\n",
      "gender       0.033107\n",
      "origin       0.047723\n",
      "race         0.015232\n",
      "religion     0.014872\n",
      "sexuality   -0.177919\n",
      "Name: attention_shap_spearman, dtype: float64\n",
      "\n",
      "Metrics = attention_shap_kendall\n",
      "hate_speech_label\n",
      "gender       0.023235\n",
      "origin       0.038814\n",
      "race         0.007516\n",
      "religion     0.010347\n",
      "sexuality   -0.157412\n",
      "Name: attention_shap_kendall, dtype: float64\n",
      "\n",
      "Metrics = attention_shap_jaccard\n",
      "hate_speech_label\n",
      "gender       0.085989\n",
      "origin       0.075370\n",
      "race         0.094758\n",
      "religion     0.081096\n",
      "sexuality    0.178402\n",
      "Name: attention_shap_jaccard, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_metrics = ['attention_shap_spearman', 'attention_shap_kendall', 'attention_shap_jaccard']\n",
    "\n",
    "for rank_metric in rank_metrics:\n",
    "  average_by_category = ucb_hate_speech_df.groupby('hate_speech_label')[rank_metric].mean()\n",
    "\n",
    "  print(f\"Metrics = {rank_metric}\")\n",
    "  print(average_by_category)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: EAT SHIT REDNECK CUNTS\n",
      "Adversarial: EAT crap cracker cunt\n"
     ]
    }
   ],
   "source": [
    "def get_first_synonym(word: str) -> str | None:\n",
    "    synsets = wordnet.synsets(word.lower())\n",
    "\n",
    "    if synsets:\n",
    "        lemmas = synsets[0].lemmas()\n",
    "        for lemma in lemmas:\n",
    "            if lemma.name() != word.lower():\n",
    "                return lemma.name()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_adversarial_example(\n",
    "    text: str, \n",
    "    scores: list[tuple], \n",
    "    replacements: int = 5\n",
    ") -> str:\n",
    "    top_tokens = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    words = word_tokenize(text)    \n",
    "    adversarial = words.copy()\n",
    "    replaced = 0\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if replaced >= replacements:\n",
    "            break\n",
    "        \n",
    "        for top_token, score in top_tokens:\n",
    "            if word.lower() == top_token.lower() or top_token.lower() in word.lower():\n",
    "                synonym = get_first_synonym(word)\n",
    "                \n",
    "                if synonym:\n",
    "                    adversarial[i] = synonym\n",
    "                    replaced += 1\n",
    "                    break\n",
    "    if replaced == 0:\n",
    "        return None\n",
    "        \n",
    "    return \" \".join(adversarial)\n",
    "\n",
    "n_sample = 93\n",
    "text = ucb_hate_speech_df.iloc[n_sample][\"text\"]\n",
    "scores = ast.literal_eval(ucb_hate_speech_df.iloc[n_sample][\"lime_scores\"])\n",
    "adversarial = create_adversarial_example(text, scores)\n",
    "\n",
    "print(f\"Original: {text}\")\n",
    "print(f\"Adversarial: {adversarial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adversarial_examples(row):\n",
    "    global tokenizer\n",
    "    attention_adversarial_scores = None\n",
    "    attention_adversarial_probs = None\n",
    "    lime_adversarial_scores = None\n",
    "    lime_adversarial_probs = None\n",
    "    shap_adversarial_scores = None\n",
    "    shap_adversarial_probs = None\n",
    "    \n",
    "    text = row[\"text\"]\n",
    "    \n",
    "    # get default predictions\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    outputs = model(**inputs)\n",
    "    default_probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "    \n",
    "    attention = ast.literal_eval(row[\"attention_scores\"])\n",
    "    lime = ast.literal_eval(row[\"lime_scores\"])\n",
    "    shap = ast.literal_eval(row[\"shap_scores\"])\n",
    "    \n",
    "    # compute adversarial examples\n",
    "    attention_adversarial = create_adversarial_example(text, attention)\n",
    "    lime_adversarial = create_adversarial_example(text, lime)\n",
    "    shap_adversarial = create_adversarial_example(text, shap)\n",
    "    \n",
    "    # compute attention adversarial\n",
    "    if attention_adversarial:\n",
    "        inputs = tokenizer(attention_adversarial, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        outputs = model(**inputs)\n",
    "        attention_adversarial_scores = compute_attention_scores(outputs.attentions, tokens)\n",
    "        attention_adversarial_probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "    \n",
    "    # compute LIME adversarial\n",
    "    if lime_adversarial:\n",
    "        inputs = tokenizer(lime_adversarial, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        outputs = model(**inputs)\n",
    "        lime_adversarial_scores = compute_lime_scores(lime_adversarial, tokens)\n",
    "        lime_adversarial_probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "    \n",
    "    # compute SHAP adversarial\n",
    "    if shap_adversarial:\n",
    "        inputs = tokenizer(shap_adversarial, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        outputs = model(**inputs)\n",
    "        shap_adversarial_scores = compute_shap_scores(shap_adversarial)\n",
    "        shap_adversarial_probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'text_probs': default_probs,\n",
    "        'attention_adversarial_scores': attention_adversarial_scores,\n",
    "        'attention_adversarial_probs': attention_adversarial_probs,\n",
    "        'lime_adversarial_scores': lime_adversarial_scores,\n",
    "        'lime_adversarial_probs': lime_adversarial_probs,\n",
    "        'shap_adversarial_scores': shap_adversarial_scores,\n",
    "        'shap_adversarial_probs': shap_adversarial_probs\n",
    "    })\n",
    "\n",
    "\n",
    "ucb_hate_speech_df[[\n",
    "    'text_probs',\n",
    "    'attention_adversarial_scores',\n",
    "    'attention_adversarial_probs',\n",
    "    'lime_adversarial_scores',\n",
    "    'lime_adversarial_probs',\n",
    "    'shap_adversarial_scores',\n",
    "    'shap_adversarial_probs'\n",
    "]] = ucb_hate_speech_df.apply(compute_adversarial_examples, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVERSARIAL ROBUSTNESS EVALUATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Adversarial Robustness Analysis: attention_adversarial_probs\n",
      "================================================================================\n",
      "\n",
      "Category             Flip Rate       CD Mean         CD Std          # Flips    # Total   \n",
      "--------------------------------------------------------------------------------\n",
      "gender                 1.04%         -0.0785        0.2790             1       96\n",
      "origin                 7.41%         -0.0404        0.3505             6       81\n",
      "race                   3.68%         -0.0693        0.3023             6      163\n",
      "religion               6.86%          0.0102        0.3457             7      102\n",
      "sexuality              5.17%          0.0027        0.3110             3       58\n",
      "--------------------------------------------------------------------------------\n",
      "OVERALL                4.60%         -0.0418        0.3174\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Adversarial Robustness Analysis: lime_adversarial_probs\n",
      "================================================================================\n",
      "\n",
      "Category             Flip Rate       CD Mean         CD Std          # Flips    # Total   \n",
      "--------------------------------------------------------------------------------\n",
      "gender                 1.04%         -0.0785        0.2790             1       96\n",
      "origin                 7.41%         -0.0404        0.3505             6       81\n",
      "race                   3.68%         -0.0693        0.3023             6      163\n",
      "religion               6.86%          0.0102        0.3457             7      102\n",
      "sexuality              5.17%          0.0027        0.3110             3       58\n",
      "--------------------------------------------------------------------------------\n",
      "OVERALL                4.60%         -0.0418        0.3174\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Adversarial Robustness Analysis: shap_adversarial_probs\n",
      "================================================================================\n",
      "\n",
      "Category             Flip Rate       CD Mean         CD Std          # Flips    # Total   \n",
      "--------------------------------------------------------------------------------\n",
      "gender                 9.38%         -0.0638        0.3018             9       96\n",
      "origin                12.35%         -0.0222        0.3673            10       81\n",
      "race                   6.13%         -0.0537        0.2799            10      163\n",
      "religion               6.86%          0.0253        0.2451             7      102\n",
      "sexuality              6.90%          0.0166        0.2218             4       58\n",
      "--------------------------------------------------------------------------------\n",
      "OVERALL                8.00%         -0.0258        0.2888\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_flip_rate_and_cd(df: pd.DataFrame, adversarial_metric: str):\n",
    "    \"\"\"\n",
    "    Compute flip rate and confidence distribution for adversarial examples.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with original and adversarial predictions\n",
    "    adversarial_metric : str\n",
    "        Column name for adversarial probabilities\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Flip rate, CD mean, and CD std per hate speech category\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract original hate speech probability (class 1)\n",
    "    original_hate_probs = df['text_probs'].apply(\n",
    "        lambda x: x[0, 1] if x is not None else np.nan\n",
    "    )\n",
    "    original_predictions = original_hate_probs >= 0.5\n",
    "    \n",
    "    # extract adversarial hate speech probability (class 1)\n",
    "    adversarial_hate_probs = df[adversarial_metric].apply(\n",
    "        lambda x: x[0, 1] if x is not None else np.nan\n",
    "    )\n",
    "    adversarial_predictions = adversarial_hate_probs >= 0.5\n",
    "    \n",
    "    # compute flips: was hate speech (1), now is not hate speech (0)\n",
    "    flips = original_predictions & ~adversarial_predictions\n",
    "    \n",
    "    # compute confidence distribution: CD = p_original - p_adversarial\n",
    "    cd = original_hate_probs - adversarial_hate_probs\n",
    "    \n",
    "    # group by hate_speech_label and compute metrics\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Adversarial Robustness Analysis: {adversarial_metric}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"{'Category':<20} {'Flip Rate':<15} {'CD Mean':<15} {'CD Std':<15} {'# Flips':<10} {'# Total':<10}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    for label in sorted(df['hate_speech_label'].unique()):\n",
    "        mask = df['hate_speech_label'] == label\n",
    "        \n",
    "        # flip rate calculation\n",
    "        label_flips = flips[mask].sum()\n",
    "        label_total = mask.sum()\n",
    "        label_flip_rate = (label_flips / label_total * 100) if label_total > 0 else 0\n",
    "        \n",
    "        # confidence distribution (CD) statistics\n",
    "        label_cd = cd[mask].dropna()\n",
    "        label_cd_mean = label_cd.mean()\n",
    "        label_cd_std = label_cd.std()\n",
    "        \n",
    "        results[label] = {\n",
    "            'flip_rate': label_flip_rate,\n",
    "            'cd_mean': label_cd_mean,\n",
    "            'cd_std': label_cd_std,\n",
    "            'num_flips': label_flips,\n",
    "            'total_samples': label_total\n",
    "        }\n",
    "        \n",
    "        print(f\"{str(label):<20} {label_flip_rate:>6.2f}%        {label_cd_mean:>8.4f}      {label_cd_std:>8.4f}      {label_flips:>8} {label_total:>8}\")\n",
    "    \n",
    "    # overall statistics\n",
    "    overall_flip_rate = (flips.sum() / len(df) * 100)\n",
    "    overall_cd_mean = cd.dropna().mean()\n",
    "    overall_cd_std = cd.dropna().std()\n",
    "    \n",
    "    print(f\"{'-'*80}\")\n",
    "    print(f\"{'OVERALL':<20} {overall_flip_rate:>6.2f}%        {overall_cd_mean:>8.4f}      {overall_cd_std:>8.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVERSARIAL ROBUSTNESS EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics = ['attention_adversarial_probs', 'lime_adversarial_probs', 'shap_adversarial_probs']\n",
    "for metric in metrics:\n",
    "    compute_flip_rate_and_cd(ucb_hate_speech_df, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb_hate_speech_df.to_csv(\"hate_speech_with_explainers_adversarial.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
